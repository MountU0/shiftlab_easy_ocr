{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import VisionEncoderDecoderModel, TrOCRProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VisionEncoderDecoderModel.from_pretrained(\"./model_saved\")\n",
    "# model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-small-stage1\").to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-small-handwritten\", \"cointegrated/LaBSE-en-ru\")\n",
    "# calling the processor is equivalent to calling the feature extractor\n",
    "image = Image.open(r\"C:\\Transformer-Based-OCR\\imgs\\00e8a9ca1e7c44b3b5b3c6fe7364378b.png\").convert(\"RGB\")\n",
    "pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "print(pixel_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = model.generate(pixel_values)\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EASY OCR CRAFT + TROCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([[[161, 595, 177, 219], [71, 681, 217, 262], [121, 251, 271, 307], [350, 432, 278, 310], [481, 605, 275, 311], [121, 185, 309, 345], [195, 683, 308, 349], [35, 51, 353, 385], [241, 313, 349, 387], [354, 384, 350, 382], [396, 506, 350, 380], [122, 632, 386, 436], [37, 53, 407, 457], [213, 547, 427, 471], [88, 197, 468, 513], [227, 357, 471, 511], [370, 402, 478, 508], [446, 514, 476, 506], [537, 647, 476, 512], [84, 226, 510, 542], [326, 658, 506, 536], [120, 164, 548, 572], [180, 224, 546, 576], [233, 269, 549, 569], [325, 619, 527, 572], [632, 676, 538, 562], [308, 474, 562, 594], [494, 528, 564, 596], [539, 676, 560, 592], [88, 112, 584, 610], [120, 166, 582, 606], [180, 220, 580, 610], [233, 273, 583, 603], [314, 528, 592, 624], [548, 612, 588, 620], [33, 53, 603, 629], [89, 107, 609, 635], [122, 254, 608, 640], [398, 430, 622, 646], [452, 550, 620, 646], [99, 259, 637, 675], [313, 507, 643, 681], [520, 552, 650, 674], [560, 648, 648, 676], [84, 670, 670, 707], [88, 122, 706, 736], [132, 244, 706, 736], [252, 376, 706, 732], [396, 460, 708, 734], [512, 640, 704, 730], [86, 144, 738, 768], [162, 306, 740, 766], [86, 166, 768, 800], [186, 292, 772, 798], [37, 53, 803, 835], [88, 176, 798, 826], [210, 292, 802, 826], [298, 396, 800, 826], [402, 474, 800, 824], [506, 544, 796, 826], [551, 579, 803, 821], [95, 163, 827, 863], [214, 254, 830, 862], [271, 297, 835, 853], [322, 406, 832, 858], [87, 547, 849, 893], [555, 687, 845, 885], [86, 348, 889, 922], [382, 472, 886, 918], [509, 527, 887, 915], [600, 652, 888, 912], [85, 340, 920, 950], [386, 434, 920, 944], [443, 673, 911, 947], [85, 159, 947, 985], [182, 428, 946, 978], [449, 489, 955, 973], [492, 562, 943, 980], [567, 613, 953, 973], [626, 680, 944, 970], [115, 312, 973, 1013], [385, 405, 971, 997], [414, 476, 974, 1002], [492, 564, 972, 998], [85, 141, 1005, 1041], [154, 218, 1008, 1036], [244, 314, 1006, 1036], [334, 478, 1008, 1038], [475, 683, 995, 1045]]], [[[[547.5423042384429, 889.27961296691], [599.1480004188601, 872.9056995916114], [607.4576957615571, 899.72038703309], [554.8519995811399, 916.0943004083886]]]])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import easyocr\n",
    "\n",
    "old_reader = easyocr.Reader(['ru'])\n",
    "\n",
    "craft_result = old_reader.detect(r\"C:\\shiftlab_easy_ocr\\test\\1.jpg\")\n",
    "\n",
    "print(craft_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import VisionEncoderDecoderModel, TrOCRProcessor\n",
    "\n",
    "class TrOCR():\n",
    "    def __init__(self) -> None:\n",
    "        self.easy_craft = easyocr.Reader(['ru'])\n",
    "        self.model = VisionEncoderDecoderModel.from_pretrained(\"./doc2text/weights/model_saved\")\n",
    "        self.processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-small-handwritten\",\n",
    "                                                         \"cointegrated/LaBSE-en-ru\")\n",
    "        \n",
    "    def generate(self, image_path:str) -> list:\n",
    "        \"\"\"\n",
    "        Will return:\n",
    "        [\n",
    "        ([[x_min, x_max, y_min, y_max],...], \"predict\", conf?),\n",
    "        ...\n",
    "        ]\n",
    "        \"\"\"\n",
    "        #open image with russian path(if you don't have cyr symbols, just use img = cv2.read(image_path))\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            chunk = f.read()\n",
    "            chunk_arr = np.frombuffer(chunk, dtype=np.uint8)\n",
    "            img = cv2.imdecode(chunk_arr, cv2.IMREAD_UNCHANGED)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        #get bboxes and small images according to them by using a craft_EasyOCR\n",
    "        cropped_images = []\n",
    "        bboxes = self.easy_craft.detect(image_path)\n",
    "        for box in bboxes[0][0]:\n",
    "            x_min, x_max, y_min, y_max = box\n",
    "            cropped_image = img[y_min:y_max, x_min:x_max]\n",
    "            cropped_images.append(cropped_image)\n",
    "            break\n",
    "\n",
    "        #TrOCR model\n",
    "        pixel_values = self.processor(cropped_images, return_tensors=\"pt\").pixel_values\n",
    "        generated_ids = self.model.generate(pixel_values)\n",
    "        generated_text = self.processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "        print(generated_text)\n",
    "\n",
    "        \n",
    "model = TrOCR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inference_file.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
     ]
    }
   ],
   "source": [
    "from TrOCR_inference import TrOCR\n",
    "\n",
    "model = TrOCR(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['эталю', 'Министерство нефтяной промышлсниости СССР', 'ИВВ.', '5045', 'У правление полевой', 'промысловой', 'геофизики', 'Трест, ТАТНБФГЕГЕФФИЭИКА', 'Бугульмиская промыслово-теофизическаи контора', 'Боковой,', 'индукционный наротаж', 'СКВ', 'Же', 'ИСОО', 'УБР', 'Данакоейские', 'РИТС', 'Мо', 'Площаль', 'Илькееваская', 'Ат', 'февдаля', '1977', 'БК', 'НК.', 'тип', 'аппаратуры. БК-7', 'тип', 'аппаратуры. ПМК-2 ф', '30ня', '1.21 1', 'зона', 'Ф 0. 75', 'Забой', '1742', 'Альтитула', 'стола', 'ротора', '208.05', 'И.', 'СКВ.', \"ИК'У илинение\", '20', 'г.П.', '1720', 'И.', '1.23 м', 'башмак', 'коня.', '010', 'добавки', 'Раствор глинистй', 'вязкость', '32', 'сек.', 'Ул.', 'вес', '1.22', 'Ул-сопр. р-ра', '0.9', 'ОМ', 'Примечание;', 'Маспитаб глубин', '1:200', 'Начальник партны', 'Митиласов', 'Оператор упр.', 'из:ят.', 'полнграф.', 'кннж.', 'торг. зак. Ме', '857. т. 3000.']\n"
     ]
    }
   ],
   "source": [
    "model.generate(r\"C:\\shiftlab_easy_ocr\\test\\2.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
